1. Give me a few reasons why we use dimensionality reduction.
2. What is the curse of dimensionality?
3. Which do you think the curse of dimensionality is likely to have the larger impact : KNN or decision tree.  Why?
4. What is PCA?
5. What do the eigenvalues reflect in PCA?
6. How do you know how many dimensions to use after applying PCA?
7. What is one potential problem with PCA?
8. What "trick" might we use to make it possible for PCA to handle non-linear data?
9. What sorts of kernels might we use in PCA?
10. What is the difference between PCA and factor analysis?
11. When is factor analysis typically used?
12. When would you use factor analysis instead of regression?
13. What kind of tests might you run to determine whether factor analysis is possible?
14. What does rotation accomplish in factor analysis?
15. How, in general, do manifold methods work?
16. What is the primary difference between tSNE and UMAP?
17. What makes tSNE difficult to use in a machine learning pipeline?
18. How does the min dist parameter influence the behaviors of UMAP?
19. How does the nearest neighbor parameter influence the behavior of tSNE?


